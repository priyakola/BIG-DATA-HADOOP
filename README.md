# BIG-DATA-HADOOP
Data Analysis using Spark
Execution steps:

Step1:Install cloudera centos in virtual machine.

Step2:Required softwares will be installed by default in this OS.

Step3:Collect Streaming log data as input to the System.

Step4:Dynamically insert the log data into HDFS using flume.

Step4:Process the Streaming log data using Spark-Scala.

Step5:Insert the Processed data into the HDFS. 

Step6:Store the data into Hive tables using Hql.

Step7:Install Tableau desktop  

Step8:Connect the Hive to Tableau using ODBC Drivers.

Step9:Visualize the Hive data to tableau in pie diagrams/bar charts....etc

Step10:stop running all the processess. 
